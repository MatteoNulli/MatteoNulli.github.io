<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Matteo Nulli </title> <meta name="author" content="Matteo Nulli"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://matteonulli.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">other stuff </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Matteo</span> Nulli </h1> <p class="desc">Applied Researcher @ <a href="https://www.ebay.com" rel="external nofollow noopener" target="_blank">eBay</a>, AI @ <a href="https://www.uva.nl" rel="external nofollow noopener" target="_blank">University of Amsterdam</a>,</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/presentazione.jpeg?af7935890f5036f2502a651bab4e019e" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="presentazione.jpeg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>Science Park, 1098 XH</p> <p>Amsterdam, The Netherlands</p> </div> </div> <div class="clearfix"> <p>📌 Hi, this is Matteo, an Applied Researcher at eBay with the Foundation Models Team. My work at eBay, focuses on reaserch in multimodal learning, inference optimization and multimodal search reasoning with <a href="https://www.seyyedhadihashemi.com/" rel="external nofollow noopener" target="_blank">Hadi Hashemi</a> and <a href="https://www.linkedin.com/in/khadivi/" rel="external nofollow noopener" target="_blank">Shahram Khadivi</a>. I am also a MSc <a href="https://ivi.fnwi.uva.nl/ellis/people/" rel="external nofollow noopener" target="_blank">ELLIS Honours</a> graduate in <a href="https://www.uva.nl/shared-content/programmas/en/masters/artificial-intelligence/artificial-intelligence.html" rel="external nofollow noopener" target="_blank">Artificial Intelligence</a> at the University of Amsterdam. For my master thesis, I was lucky to be suprevised by <a href="https://yukimasano.github.io/" rel="external nofollow noopener" target="_blank">Yuki Asano</a> at <a href="https://fundamentalailab.github.io/" rel="external nofollow noopener" target="_blank">FunAI Lab</a>, <a href="https://ivonajdenkoska.github.io/" rel="external nofollow noopener" target="_blank">Ivona Najdenkoska</a> and <a href="https://mmderakhshani.github.io/" rel="external nofollow noopener" target="_blank">Mohammad Mahdi Derakhshani</a> to investigate Compositional Reasoning in Multimodal Foundation Models.</p> <p>🔙 Previously, I graduated from <a href="https://www.unibocconi.it/en" rel="external nofollow noopener" target="_blank">Bocconi University</a> with a BSc in <a href="https://www.unibocconi.eu/wps/wcm/connect/bocconi/sitopubblico_en/navigation+tree/home/programs/bachelor+of+science/mathematical+and+computing+sciences+for+artificial+intelligence/mathematical+and+computing+sciences+for+artificial+intelligence/" rel="external nofollow noopener" target="_blank">Mathematical and Computing Sciences for AI</a> and was an exchange student in Applied Mathematics and Computer Science at the <a href="https://www.sydney.edu.au" rel="external nofollow noopener" target="_blank">University of Sydney</a> with a full-ride scholarship.</p> <p>💭 My research interes lies in the intersection between Language and Vision. I am particularly interested in linking multiple modalities together. Recently I studied visual representation learning and how to leverage it for extensive image-understanding in MLLMs.</p> <p>📚 Currently working at ebay on multimodal search reasoning and VLMs inference optimization as well as continuing my research into Compositional Reasoning.</p> <p>Always open to hear about possible research collaborations, feel free to reach out.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Aug 18, 2025</th> <td> Just started working as full time Applied Researcher at eBay Foundation Models Team with <a href="https://nl.linkedin.com/in/hadi-hashemi-75a82649" rel="external nofollow noopener" target="_blank">Hadi</a> and <a href="https://www.linkedin.com/in/khadivi/" rel="external nofollow noopener" target="_blank">Shahram</a>. Excited to (re-)start. 👾 </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 20, 2025</th> <td> Fortunate to visit Prof. <a href="https://www.novatalent.com/111/italy/student-list/2025" rel="external nofollow noopener" target="_blank">Yuki Asano</a> at <a href="https://fundamentalailab.github.io/" rel="external nofollow noopener" target="_blank">FunAI Lab in UTN Nuremberg</a> as part of <a href="https://ivi.fnwi.uva.nl/ellis/people/" rel="external nofollow noopener" target="_blank">ELLIS Honours program</a> for my master thesis on Compositional Reasoning in Vision-Language. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 26, 2025</th> <td> Part of <a href="https://www.novatalent.com/111/italy/student-list/2025" rel="external nofollow noopener" target="_blank">Nova 111 Student List</a> for 2025, among the most promising itaian students in my field! Read more under <code class="language-plaintext highlighter-rouge">other stuff/</code>. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 01, 2024</th> <td> Going to NeurIPS! Our paper <a href="https://arxiv.org/abs/2410.18952" rel="external nofollow noopener" target="_blank">Dynamic Vocabulary Pruning in Early-Exit LLMs</a> was just accepted to <a href="https://neurips2024-enlsp.github.io/" rel="external nofollow noopener" target="_blank">NeurIPS Efficient Natural Language and Speech Processing (ENLSP-IV) Workshop</a> 🚀 </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 15, 2024</th> <td> Today, I started working at eBay, joining the Foundation Models Team in the Amsterdam office. The internship will focus on multimodal research and development for data, architecture and pre-training. Excited to start! </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 03, 2024</th> <td> <a href="https://arxiv.org/abs/2407.15487" rel="external nofollow noopener" target="_blank">In-Context Learning Improves Compositional Understanding of Vision-Language Models</a> was just published in <a href="https://icml-fm-wild.github.io" rel="external nofollow noopener" target="_blank">ICML Workshop on Foundation Models in the Wild</a> 🙌 </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 01, 2024</th> <td> My first paper <a href="https://openreview.net/forum?id=QdeBbK5CSh" rel="external nofollow noopener" target="_blank">‘Explaining RL Decisions with Trajectories’: A Reproducibility Study</a> was just published in <a href="https://www.jmlr.org/tmlr/papers/#" rel="external nofollow noopener" target="_blank">Transactions on Machine Learning Research</a> 🎊 </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 01, 2023</th> <td> I joined the University of Amsterdam to pursue the <a href="https://www.uva.nl/shared-content/programmas/en/masters/artificial-intelligence/artificial-intelligence.html" rel="external nofollow noopener" target="_blank">Master in Aritifcial Intelligence</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 25, 2023</th> <td> I graduated from Bocconi University and was among the first 9 graduates in the history of the course <a href="https://www.unibocconi.eu/wps/wcm/connect/bocconi/sitopubblico_en/navigation+tree/home/programs/bachelor+of+science/mathematical+and+computing+sciences+for+artificial+intelligence/mathematical+and+computing+sciences+for+artificial+intelligence/" rel="external nofollow noopener" target="_blank">Mathematical and Computing Sciences for AI</a>! 🎓 </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 10, 2023</th> <td> Just landed in Australia to join the University of Sydney for a full semester, I will be taking <a href="https://www.sydney.edu.au/units/COMP5329" rel="external nofollow noopener" target="_blank">Deep Learning</a>, <a href="https://www.sydney.edu.au/units/STAT3921" rel="external nofollow noopener" target="_blank">Stochastic Processes</a> and <a href="https://www.sydney.edu.au/units/DATA2901" rel="external nofollow noopener" target="_blank">Big Data and Data Diversity</a> courses as well as surfing 🏄 </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="https://neurips2024-enlsp.github.io/" rel="external nofollow noopener" target="_blank">ENLSP@NeurIPS</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/ee-nips.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ee-nips.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vincenti2024dynamic" class="col-sm-8"> <div class="title">Dynamic Vocabulary Pruning in Early-Exit LLMs</div> <div class="author"> <a href="https://github.com/JortVincenti" rel="external nofollow noopener" target="_blank">Jort Vincenti*</a>, <a href="https://karim-abdel.github.io" rel="external nofollow noopener" target="_blank">Karim Abdel Sadek*</a>, <a href="https://joanvelja.vercel.app" rel="external nofollow noopener" target="_blank">Joan Velja*</a>, <em>Matteo Nulli*</em>, and Metod Jazbec </div> <div class="periodical"> <em>NeurIPS Efficient Natural Language and Speech Processing</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2410.18952" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2410.18952" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Increasing the size of large language models (LLMs) has been shown to lead to better performance. However, this comes at the cost of slower and more expensive inference. Early-exiting is a promising approach for improving the efficiency of LLM inference by enabling next token prediction at intermediate layers. Yet, the large vocabulary size in modern LLMs makes the confidence estimation required for exit decisions computationally expensive, diminishing the efficiency gains. To address this, we propose dynamically pruning the vocabulary at test time for each token. Specifically, the vocabulary is pruned at one of the initial layers, and the smaller vocabulary is then used throughout the rest of the forward pass. Our experiments demonstrate that such post-hoc dynamic vocabulary pruning improves the efficiency of confidence estimation in early-exit LLMs while maintaining competitive performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vincenti2024dynamic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic Vocabulary Pruning in Early-Exit LLMs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vincenti*, Jort and Sadek*, Karim Abdel and Velja*, Joan and Nulli*, Matteo and Jazbec, Metod}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2410.18952}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NeurIPS Efficient Natural Language and Speech Processing}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2410.18952}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="https://icml-fm-wild.github.io" rel="external nofollow noopener" target="_blank">FMW@ICML</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/vlm_comp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vlm_comp.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nulli2024context" class="col-sm-8"> <div class="title">In-Context Learning Improves Compositional Understanding of Vision-Language Models</div> <div class="author"> <em>Matteo Nulli</em>, Anesa Ibrahimi, Avik Pal, Hoshe Lee, and Ivona Najdenkoska </div> <div class="periodical"> <em>In ICML 2024 Workshop on Foundation Models in the Wild</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2407.15487" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2407.15487" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.linkedin.com/feed/update/urn:li:activity:7238837758444601344/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Vision-Language Models (VLMs) have shown remarkable capabilities in a large number of downstream tasks. Nonetheless, compositional image understanding remains a rather difficult task due to the object bias present in training data. In this work, we investigate the reasons for such a lack of capability by performing an extensive bench-marking of compositional understanding in VLMs. We compare contrastive models with generative ones and analyze their differences in architecture, pre-training data, and training tasks and losses. Furthermore, we leverage In-Context Learning (ICL) as a way to improve the ability of VLMs to perform more complex reasoning and understanding given an image. Our extensive experiments demonstrate that our proposed approach outperforms baseline models across multiple compositional understanding datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nulli2024context</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{In-Context Learning Improves Compositional Understanding of Vision-Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nulli, Matteo and Ibrahimi, Anesa and Pal, Avik and Lee, Hoshe and Najdenkoska, Ivona}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICML 2024 Workshop on Foundation Models in the Wild}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2407.15487}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CV}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.15487}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="https://www.jmlr.org/tmlr/" rel="external nofollow noopener" target="_blank">TMLR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/xrl_repro.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xrl_repro.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sadek2024explaining" class="col-sm-8"> <div class="title">’Explaining RL Decisions with Trajectories’: A Reproducibility Study</div> <div class="author"> <a href="https://karim-abdel.github.io" rel="external nofollow noopener" target="_blank">Karim Abdel Sadek*</a>, <em>Matteo Nulli*</em>, <a href="https://joanvelja.vercel.app" rel="external nofollow noopener" target="_blank">Joan Velja*</a>, and <a href="https://github.com/JortVincenti" rel="external nofollow noopener" target="_blank">Jort Vincenti*</a> </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2024 </div> <div class="periodical"> Reproducibility Certification </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2411.07200" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2411.07200" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This work investigates the reproducibility of the paper "Explaining RL decisions with trajectories“ by Deshmukh et al. (2023). The original paper introduces a novel approach in explainable reinforcement learning based on the attribution decisions of an agent to specific clusters of trajectories encountered during training. We verify the main claims from the paper, which state that (i) training on less trajectories induces a lower initial state value, (ii) trajectories in a cluster present similar high-level patterns, (iii) distant trajectories influence the decision of an agent, and (iv) humans correctly identify the attributed trajectories to the decision of the agent. We recover the environments used by the authors based on the partial original code they provided for one of the environments (Grid-World), and implemented the remaining from scratch (Seaquest and HalfCheetah, Breakout, Q*Bert). While we confirm that (i), (ii), and (iii) partially hold, we extend on the largely qualitative experiments from the authors by introducing a quantitative metric to further support (iii), and new experiments and visual results for (i). Moreover, we investigate the use of different clustering algorithms and encoder architectures to further support (ii). We could not support (iv), given the limited extent of the original experiments. We conclude that, while some of the claims can be supported, further investigations and experiments could be of interest. We recognize the novelty of the work from the authors and hope that our work paves the way for clearer and more transparent approaches.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sadek2024explaining</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{'Explaining {RL} Decisions with Trajectories{\textquoteright}: A Reproducibility Study}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sadek*, Karim Abdel and Nulli*, Matteo and Velja*, Joan and Vincenti*, Jort}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions on Machine Learning Research}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2835-8856}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2411.07200}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Reproducibility Certification}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6D%61%74%74%65%6F.%6E%75%6C%6C%69@%6F%75%74%6C%6F%6F%6B.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=WR5G-XcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/MatteoNulli" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/matteonulli" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/matteo_nulli" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">The best way to reach me is by email: matteo.nulli@outlook.com </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Matteo Nulli. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>