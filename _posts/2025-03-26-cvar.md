---
layout: post
title: "Perception, Localization, Planning and Control \n on RAE Robots"
date: 2025-01-20 14:24:00
description: Computer Vision for Autonomour Robots
tags: Computer-Vision Robotics
---


##### R. den Braber, M. Nulli, D. Zegveld
###### University of Amsterdam
###### Links: üìù [Blogpost](https://matteonulli.github.io/blog/2025/var/) | üßë‚Äçüíª [Code]()
<br>

## Introduction

In this blogpost we go over our process of building an integrated perception‚Äìlocalization‚Äìplanning‚Äìcontrol pipeline on the RAE robot. 

### Camera Calibration and Line Following

In this section we demonstrate the effectiveness of our line-following pipeline by using a RAE robot to move parallel to the lines spanned by ceiling lights.

We began with camera calibration, which is shown to reduce distortion resulting in improved navigation accuracy. We do so comparing two algorithms of differing complexity, ultimately using Zhang's [[1](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr98-71.pdf)] camera calibration technique. 

Thereafter we developed a line‚Äëfollowing algorithm. 

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
    <a id="figure1"></a>
        {% include figure.liquid loading="eager" path="./assets/img/line_following_v2.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 1: Overview of the full pipeline, where the lower blue part specifically covers the Line Selection and Line Following procedure. With the output of the Line Following procedure a Movement Update is calculated to direct the robot along the direction of the ceiling lights. Additionally, when no lines are detected the RAE robot is instructed to spin around until it finds the wanted ceiling lines (here in red).
</div>

First step is edege detection through an optimized version of the Canny edge detection algorithm. 
The next step is line detection, whose aim is to return a list of all lines that are spanned by the ceiling lights. It leverages a fine-tuned version of the Hough transform in addition to our triangular region of interest see blue line in [Figure 2](#figure2). Both the edge and line detection stages are refined by tuning the parameters and by adding additional steps such as image dilation to make the ceiling lines more prominent in the resulting image. This increases the robustness of our algorithm so that it can properly detect lines in difficult conditions, for example, at different angles, lighting conditions, and deal with gaps between the ceiling lights.

Lastly, the line-following algorithm implements a way to consistently select the closest line, which removes the distraction of multiple detected lines. 
Next, using the selected line, we calculate a vanishing point to move towards instead of blindly following the line as this proves to increase navigational consistency and accuracy see [Figure 2](#figure2). 
Additionally, in an ablation study we found that utilizing this vanishing point approach allows our robot to still perform well, even without camera calibration, with only a slight potential reduction in navigational accuracy. This robustness highlights the strengths and adaptability of our pipeline (see [Figure 1](#figure1)) which results in a stable and accurate ceiling light line following algorithm for the RAE robot.

### Localization and Curlying Match


<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/IMG_6020.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/IMG_6018.mp4" class="img-fluid rounded z-depth-1" controls=true %}
    </div>
</div>
<div class="caption">
    A simple, elegant caption looks good between video rows, after each row, or doesn't have to be there at all.
</div>



## Citation

If you use this work, please cite:

```bibtex
@misc{denbraber2025cvar,
  author  = {den Braber, R., and Nulli, M., and Zegveld, D.},
  title   = {Perception, Localization, Planning and Control on RAE Robots},
  howpublished  = {https://matteonulli.github.io/blog/2025/cvar/},
  year    = {2025},
}
```
